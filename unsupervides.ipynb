{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrique d'évaluation utilisé\n",
    "Log Likelihood : Plus la vraisemblance logarithmique est élevée, meilleur est le modèle. Vous pouvez obtenir ce score en utilisant la méthode score de l'objet LDA.  \n",
    "  \n",
    "Perplexity : La perplexité est une mesure de la qualité du modèle. Une perplexité plus faible indique un meilleur modèle. Vous pouvez obtenir ce score en utilisant la méthode perplexity.  \n",
    "  \n",
    "Coherence Score : Le score de cohérence mesure la cohérence sémantique des sujets générés par le modèle LDA. Un score de cohérence plus élevé indique que les mots les plus importants d'un sujet sont plus sémantiquement similaires les uns aux autres. Le score de cohérence n'est pas directement disponible dans scikit-learn, mais peut être calculé en utilisant la bibliothèque Gensim.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pipeline avec les vectoriasations bag of words et tf-idf\n",
    "\n",
    "class CustomCountVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(min_df=0.10, max_df=0.5, ngram_range=(1, 1), stop_words='english')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return self.vectorizer.transform(X)\n",
    "    \n",
    "class CustomTfidfVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(min_df=0.10, max_df=0.2, ngram_range=(1, 1), stop_words='english')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return self.vectorizer.transform(X)\n",
    "\n",
    "pipeline_vec = Pipeline([\n",
    "    (\"count_vectorizer\", CustomCountVectorizer())\n",
    "])\n",
    "\n",
    "\n",
    "def create_vectors_pipeline():\n",
    "    pipeline_vec = Pipeline([\n",
    "        (\"count_vectorizer\", CustomCountVectorizer())\n",
    "    ])\n",
    "    return pipeline_vec\n",
    "\n",
    "def create_tfidf_pipeline():\n",
    "    pipeline_tfidf = Pipeline([\n",
    "        \n",
    "        (\"tfidf\", CustomTfidfVectorizer())\n",
    "    ])\n",
    "    return pipeline_tfidf\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test avec CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizer la colonne Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 58)\n",
      "(58,)\n"
     ]
    }
   ],
   "source": [
    "# Créer le pipeline de vectorisation\n",
    "pipeline_vec = create_vectors_pipeline()\n",
    "\n",
    "# Supposons que vous avez une DataFrame pandas X_fulltrain contenant les données textuelles dans une colonne 'body'\n",
    "X_fulltrain = pd.read_csv(\"Data/X_train.csv\", index_col=0, lineterminator='\\n')\n",
    "\n",
    "# Transformer les données textuelles en utilisant le pipeline\n",
    "transformed_data_body = pipeline_vec.fit_transform(X_fulltrain.body)\n",
    "print(transformed_data_body.shape)\n",
    "# Obtenir le transformateur CustomCountVectorizer du pipeline\n",
    "custom_count_vectorizer_body = pipeline_vec.named_steps['count_vectorizer']\n",
    "\n",
    "# Obtenir les noms des caractéristiques (mots)\n",
    "feature_names_body = custom_count_vectorizer_body.vectorizer.get_feature_names_out()\n",
    "\n",
    "# Afficher les noms des caractéristiques\n",
    "print(feature_names_body.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizer la colonne title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 1)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "pipeline_vec_title = create_vectors_pipeline()\n",
    "# Supposons que vous avez une DataFrame pandas X_fulltrain contenant les données textuelles dans une colonne 'body'\n",
    "X_fulltrain = pd.read_csv(\"Data/X_train.csv\", index_col=0, lineterminator='\\n')\n",
    "\n",
    "# Transformer les données textuelles en utilisant le pipeline\n",
    "transformed_data_title = pipeline_vec_title.fit_transform(X_fulltrain.title)\n",
    "print(transformed_data_title.shape)\n",
    "# Obtenir le transformateur CustomCountVectorizer du pipeline\n",
    "custom_count_vectorizer_title = pipeline_vec_title.named_steps['count_vectorizer']\n",
    "\n",
    "# Obtenir les noms des caractéristiques (mots)\n",
    "feature_names = custom_count_vectorizer_title.vectorizer.get_feature_names_out()\n",
    "\n",
    "# Afficher les noms des caractéristiques\n",
    "print(feature_names.shape)\n",
    "\n",
    "feature_names = np.concatenate((feature_names, feature_names_body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 59)\n"
     ]
    }
   ],
   "source": [
    "# Concaténer les deux matrices\n",
    "transformed_data = np.concatenate((transformed_data_title.toarray(), transformed_data_body.toarray()), axis=1)\n",
    "\n",
    "# Vérifier la forme de la matrice combinée\n",
    "print(transformed_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer LDA sur les données transformé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04766254 0.002      0.002      ... 0.002      0.002      0.002     ]\n",
      " [0.00263158 0.00263158 0.00263158 ... 0.00263158 0.00263158 0.00263158]\n",
      " [0.12405767 0.003125   0.003125   ... 0.07584285 0.003125   0.003125  ]\n",
      " ...\n",
      " [0.00263158 0.00263158 0.00263158 ... 0.00263158 0.07803832 0.00263158]\n",
      " [0.00714286 0.48188378 0.00714286 ... 0.00714286 0.00714286 0.38954479]\n",
      " [0.21445541 0.00555556 0.00555556 ... 0.15544558 0.00555556 0.00555556]]\n",
      "[[1.05360788e+01 5.00000009e-02 5.00000011e-02 ... 4.33241634e+00\n",
      "  5.00000010e-02 3.11210363e+01]\n",
      " [5.00000007e-02 5.00000010e-02 5.00000190e-02 ... 7.52475798e-01\n",
      "  5.00000005e-02 5.44482549e-02]\n",
      " [5.00000006e-02 5.00000007e-02 5.00000009e-02 ... 7.23394350e-01\n",
      "  5.00000003e-02 1.06296633e+01]\n",
      " ...\n",
      " [9.05724306e+01 4.17836081e+00 6.70520197e+00 ... 2.23884189e+01\n",
      "  5.00000011e-02 8.41778290e+00]\n",
      " [5.00000004e-02 5.00000002e-02 5.00000007e-02 ... 1.22247629e+01\n",
      "  2.78744835e+01 1.19832728e+01]\n",
      " [5.00000009e-02 5.00000008e-02 2.41225334e+00 ... 8.17727716e+01\n",
      "  4.20736777e+01 2.17563318e+01]]\n",
      "Log Likelihood:  -57529.9825702939\n",
      "Perplexity:  45.967356523387444\n",
      "-------Topic 0:--------\n",
      "want\n",
      "know\n",
      "implement\n",
      "android\n",
      "run\n",
      "make\n",
      "work\n",
      "problem\n",
      "user\n",
      "app\n",
      "-------Topic 1:--------\n",
      "code\n",
      "view\n",
      "new\n",
      "string\n",
      "void\n",
      "set\n",
      "override\n",
      "return\n",
      "class\n",
      "public\n",
      "-------Topic 2:--------\n",
      "follow\n",
      "know\n",
      "like\n",
      "code\n",
      "error\n",
      "work\n",
      "im\n",
      "solution\n",
      "project\n",
      "file\n",
      "-------Topic 3:--------\n",
      "run\n",
      "error\n",
      "work\n",
      "create\n",
      "new\n",
      "return\n",
      "follow\n",
      "try\n",
      "data\n",
      "string\n",
      "-------Topic 4:--------\n",
      "start\n",
      "help\n",
      "example\n",
      "say\n",
      "way\n",
      "create\n",
      "application\n",
      "want\n",
      "user\n",
      "google\n",
      "-------Topic 5:--------\n",
      "support\n",
      "issue\n",
      "start\n",
      "follow\n",
      "update\n",
      "work\n",
      "project\n",
      "error\n",
      "run\n",
      "version\n",
      "-------Topic 6:--------\n",
      "need\n",
      "make\n",
      "ive\n",
      "question\n",
      "case\n",
      "way\n",
      "look\n",
      "set\n",
      "im\n",
      "like\n",
      "-------Topic 7:--------\n",
      "know\n",
      "dont\n",
      "update\n",
      "look\n",
      "im\n",
      "way\n",
      "application\n",
      "data\n",
      "like\n",
      "time\n",
      "-------Topic 8:--------\n",
      "solution\n",
      "say\n",
      "want\n",
      "follow\n",
      "support\n",
      "way\n",
      "question\n",
      "know\n",
      "example\n",
      "problem\n",
      "-------Topic 9:--------\n",
      "user\n",
      "question\n",
      "need\n",
      "work\n",
      "want\n",
      "update\n",
      "data\n",
      "implement\n",
      "make\n",
      "change\n",
      "-------Topic 10:--------\n",
      "help\n",
      "follow\n",
      "app\n",
      "activity\n",
      "android\n",
      "code\n",
      "work\n",
      "try\n",
      "version\n",
      "gt\n",
      "-------Topic 11:--------\n",
      "set\n",
      "run\n",
      "change\n",
      "make\n",
      "follow\n",
      "im\n",
      "code\n",
      "new\n",
      "try\n",
      "ive\n",
      "-------Topic 12:--------\n",
      "true\n",
      "code\n",
      "try\n",
      "activity\n",
      "return\n",
      "method\n",
      "public\n",
      "new\n",
      "override\n",
      "void\n",
      "-------Topic 13:--------\n",
      "follow\n",
      "code\n",
      "start\n",
      "solution\n",
      "help\n",
      "try\n",
      "im\n",
      "error\n",
      "issue\n",
      "work\n",
      "-------Topic 14:--------\n",
      "implement\n",
      "data\n",
      "im\n",
      "override\n",
      "method\n",
      "return\n",
      "view\n",
      "new\n",
      "activity\n",
      "fragment\n",
      "-------Topic 15:--------\n",
      "need\n",
      "follow\n",
      "want\n",
      "work\n",
      "im\n",
      "new\n",
      "try\n",
      "project\n",
      "create\n",
      "add\n",
      "-------Topic 16:--------\n",
      "help\n",
      "add\n",
      "set\n",
      "follow\n",
      "try\n",
      "class\n",
      "true\n",
      "application\n",
      "method\n",
      "error\n",
      "-------Topic 17:--------\n",
      "need\n",
      "add\n",
      "work\n",
      "im\n",
      "want\n",
      "update\n",
      "new\n",
      "support\n",
      "android\n",
      "android\n",
      "-------Topic 18:--------\n",
      "example\n",
      "create\n",
      "im\n",
      "know\n",
      "true\n",
      "try\n",
      "way\n",
      "need\n",
      "return\n",
      "function\n",
      "-------Topic 19:--------\n",
      "set\n",
      "work\n",
      "create\n",
      "know\n",
      "dont\n",
      "update\n",
      "way\n",
      "want\n",
      "code\n",
      "view\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Créer une instance de LDA\n",
    "lda = LatentDirichletAllocation(n_components=20, \n",
    "                                n_jobs=-1,\n",
    "                                random_state=42)\n",
    "\n",
    "# Ajuster le modèle LDA aux données\n",
    "lda.fit(transformed_data)\n",
    "\n",
    "# Obtenir les sujets pour chaque document\n",
    "document_topics = lda.transform(transformed_data)\n",
    "print(document_topics)\n",
    "# Obtenir les composants du modèle LDA\n",
    "components = lda.components_\n",
    "print(components)\n",
    "# Obtenir le score de vraisemblance logarithmique\n",
    "log_likelihood = lda.score(transformed_data)\n",
    "\n",
    "# Obtenir la perplexité\n",
    "perplexity = lda.perplexity(transformed_data)\n",
    "\n",
    "print(\"Log Likelihood: \", log_likelihood)\n",
    "print(\"Perplexity: \", perplexity)\n",
    "# Pour chaque sujet, imprimer les mots les plus importants\n",
    "for i, topic in enumerate(components):\n",
    "    print(f\"-------Topic {i}:--------\")\n",
    "    # Obtenir les indices des mots les plus importants pour ce sujet\n",
    "    word_indices = topic.argsort()[-10:]\n",
    "    # Imprimer les mots correspondants\n",
    "    for index in word_indices[:10]:\n",
    "        print(f\"{feature_names[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.542213594812194\n",
      "Log Likelihood:  -57529.9825702939\n",
      "Perplexity:  45.967356523387444\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Convertir les données transformées en une liste de listes de mots\n",
    "data_words = [list(filter(None, [feature_names[index] for index in row.nonzero()[0]])) for row in transformed_data]\n",
    "# Convertir les données transformées en une liste de listes de mots\n",
    "'''data_words = []\n",
    "for row in transformed_data:\n",
    "    # Obtenir les indices des valeurs non nulles dans la ligne\n",
    "    nonzero_indices = row.nonzero()[0]\n",
    "    # Filtrer les indices pour qu'ils soient dans la plage valide\n",
    "    valid_indices = [index for index in nonzero_indices if index < len(feature_names)]\n",
    "    # Ajouter les mots correspondant aux indices valides à la liste\n",
    "    words = [feature_names[index] for index in valid_indices]\n",
    "    data_words.append(words)'''\n",
    "\n",
    "# Créer le modèle LDA de Gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# Créer un dictionnaire Gensim à partir des données\n",
    "dictionary = Dictionary(data_words)\n",
    "\n",
    "# Créer un corpus Gensim\n",
    "corpus = [dictionary.doc2bow(text) for text in data_words]\n",
    "\n",
    "# Créer le modèle LDA Gensim\n",
    "lda_gensim = LdaModel(corpus=corpus,\n",
    "                      id2word=dictionary,\n",
    "                      num_topics=20,\n",
    "                      random_state=42,\n",
    "                      passes=10,\n",
    "                      iterations=100)\n",
    "\n",
    "# Calculer le score de cohérence\n",
    "coherence_model_lda = CoherenceModel(model=lda_gensim, texts=data_words, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "print(\"Coherence Score:\", coherence_lda)\n",
    "print(\"Log Likelihood: \", log_likelihood)\n",
    "print(\"Perplexity: \", perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test avec la vectorisation Tf_Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 46)\n",
      "(46,)\n",
      "['activity' 'add' 'android' 'app' 'application' 'case' 'change' 'class'\n",
      " 'data' 'doesnt' 'dont' 'example' 'file' 'fragment' 'function' 'google'\n",
      " 'help' 'implement' 'issue' 'ive' 'know' 'look' 'make' 'method' 'need'\n",
      " 'override' 'project' 'public' 'question' 'return' 'run' 'say' 'set'\n",
      " 'solution' 'start' 'string' 'support' 'thanks' 'time' 'true' 'update'\n",
      " 'user' 'version' 'view' 'void' 'way']\n",
      "  (0, 34)\t0.8193829014871954\n",
      "  (0, 33)\t0.21759777687243947\n",
      "  (0, 22)\t0.1900043940757113\n",
      "  (0, 21)\t0.20670959394617275\n",
      "  (0, 20)\t0.19201234923918767\n",
      "  (0, 19)\t0.19355746020090633\n",
      "  (0, 18)\t0.20608271543489093\n",
      "  (0, 13)\t0.2253890821008403\n",
      "  (0, 3)\t0.18662471878631928\n",
      "  (1, 39)\t0.31183328805782573\n",
      "  (1, 35)\t0.915181764500241\n",
      "  (1, 3)\t0.2553474855667677\n",
      "  (2, 34)\t0.2693488825349901\n",
      "  (2, 29)\t0.24539032663369487\n",
      "  (2, 13)\t0.5927221306596637\n",
      "  (2, 8)\t0.5573540238560171\n",
      "  (2, 3)\t0.24539032663369487\n",
      "  (2, 2)\t0.2524744492794455\n",
      "  (2, 0)\t0.285152546972993\n",
      "  (3, 39)\t0.6501783162322662\n",
      "  (3, 22)\t0.5420459094871147\n",
      "  (3, 1)\t0.5324043473805055\n",
      "  (4, 44)\t0.3953940221816775\n",
      "  (4, 43)\t0.17464342280673623\n",
      "  (4, 42)\t0.05983072346379579\n",
      "  :\t:\n",
      "  (795, 33)\t0.24174773098760075\n",
      "  (795, 28)\t0.11625086576411116\n",
      "  (795, 26)\t0.10990669999201007\n",
      "  (795, 24)\t0.20733714728730793\n",
      "  (795, 16)\t0.11625086576411116\n",
      "  (795, 13)\t0.7512112481626753\n",
      "  (795, 10)\t0.11482556492098255\n",
      "  (795, 6)\t0.10960009499698802\n",
      "  (795, 2)\t0.10666136027985236\n",
      "  (795, 0)\t0.48186671774837786\n",
      "  (796, 45)\t0.48251326428345775\n",
      "  (796, 38)\t0.5501247191783882\n",
      "  (796, 33)\t0.2904317221441403\n",
      "  (796, 26)\t0.264080179974852\n",
      "  (796, 21)\t0.2758990657735292\n",
      "  (796, 20)\t0.25628238516044627\n",
      "  (796, 14)\t0.3041933045340096\n",
      "  (796, 10)\t0.2758990657735292\n",
      "  (797, 20)\t0.30688367103537206\n",
      "  (797, 10)\t0.3303735373260359\n",
      "  (797, 7)\t0.8925669377063751\n",
      "  (798, 26)\t0.5022367451738513\n",
      "  (798, 15)\t0.5345767908948011\n",
      "  (798, 3)\t0.4737306006584634\n",
      "  (798, 2)\t0.48740663150347424\n"
     ]
    }
   ],
   "source": [
    "# Créer le pipeline de vectorisation\n",
    "pipeline_tfidf = create_tfidf_pipeline()\n",
    "\n",
    "# Supposons que vous avez une DataFrame pandas X_fulltrain contenant les données textuelles dans une colonne 'body'\n",
    "X_fulltrain = pd.read_csv(\"Data/X_train.csv\", index_col=0, lineterminator='\\n')\n",
    "\n",
    "# Transformer les données textuelles en utilisant le pipeline\n",
    "transformed_data_body_tf = pipeline_tfidf.fit_transform(X_fulltrain.body)\n",
    "print(transformed_data_body_tf.shape)\n",
    "# Obtenir le transformateur CustomCountVectorizer du pipeline\n",
    "custom_count_tf_body = pipeline_tfidf.named_steps['tfidf']\n",
    "\n",
    "# Obtenir les noms des caractéristiques (mots)\n",
    "feature_names_body = custom_count_tf_body.vectorizer.get_feature_names_out()\n",
    "\n",
    "# Afficher les noms des caractéristiques\n",
    "print(feature_names_body.shape)\n",
    "print(feature_names_body)\n",
    "print(transformed_data_body_tf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
